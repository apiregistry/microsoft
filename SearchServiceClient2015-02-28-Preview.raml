#%RAML 1.0
title: SearchServiceClient
version: 2015-02-28-Preview
description: Client that can be used to manage and query indexes and documents, as well as manage other resources, on an Azure Search service.
mediaType:
- application/json
uses:
  commons: https://raw.githubusercontent.com/apiregistry/commons/master/commons.raml
  extras: https://raw.githubusercontent.com/apiregistry/typesExtras/master/typeExtras.raml
types:
  CjkBigramTokenFilterScripts:
    type: string
    description: Scripts that can be ignored by CjkBigramTokenFilter.
    enum:
    - han
    - hiragana
    - katakana
    - hangul
  EdgeNGramTokenFilterSide:
    type: string
    description: Specifies which side of the input an n-gram should be generated from.
    enum:
    - front
    - back
  IndexerExecutionStatus:
    type: string
    description: Represents the status of an individual indexer execution.
    enum:
    - transientFailure
    - success
    - inProgress
    - reset
  IndexerStatus:
    type: string
    description: Represents the overall indexer status.
    enum:
    - unknown
    - error
    - running
  MicrosoftStemmingTokenizerLanguage:
    type: string
    description: Lists the languages supported by the Microsoft language stemming tokenizer.
    enum:
    - arabic
    - bangla
    - bulgarian
    - catalan
    - croatian
    - czech
    - danish
    - dutch
    - english
    - estonian
    - finnish
    - french
    - german
    - greek
    - gujarati
    - hebrew
    - hindi
    - hungarian
    - icelandic
    - indonesian
    - italian
    - kannada
    - latvian
    - lithuanian
    - malay
    - malayalam
    - marathi
    - norwegianBokmaal
    - polish
    - portuguese
    - portugueseBrazilian
    - punjabi
    - romanian
    - russian
    - serbianCyrillic
    - serbianLatin
    - slovak
    - slovenian
    - spanish
    - swedish
    - tamil
    - telugu
    - turkish
    - ukrainian
    - urdu
  MicrosoftTokenizerLanguage:
    type: string
    description: Lists the languages supported by the Microsoft language tokenizer.
    enum:
    - bangla
    - bulgarian
    - catalan
    - chineseSimplified
    - chineseTraditional
    - croatian
    - czech
    - danish
    - dutch
    - english
    - french
    - german
    - greek
    - gujarati
    - hindi
    - icelandic
    - indonesian
    - italian
    - japanese
    - kannada
    - korean
    - malay
    - malayalam
    - marathi
    - norwegianBokmaal
    - polish
    - portuguese
    - portugueseBrazilian
    - punjabi
    - romanian
    - russian
    - serbianCyrillic
    - serbianLatin
    - slovenian
    - spanish
    - swedish
    - tamil
    - telugu
    - thai
    - ukrainian
    - urdu
    - vietnamese
  PhoneticEncoder:
    type: string
    description: Identifies the type of phonetic encoder to use with a PhoneticTokenFilter.
    enum:
    - metaphone
    - doubleMetaphone
    - soundex
    - refinedSoundex
    - caverphone1
    - caverphone2
    - cologne
    - nysiis
    - koelnerPhonetik
    - haasePhonetik
    - beiderMorse
  ScoringFunctionAggregation:
    type: string
    description: Defines the aggregation function used to combine the results of all the scoring functions in a scoring profile.
    enum:
    - sum
    - average
    - minimum
    - maximum
    - firstMatching
  ScoringFunctionInterpolation:
    type: string
    description: Defines the function used to interpolate score boosting across a range of documents.
    enum:
    - linear
    - constant
    - quadratic
    - logarithmic
  SnowballTokenFilterLanguage:
    type: string
    description: The language to use for a Snowball token filter.
    enum:
    - armenian
    - basque
    - catalan
    - danish
    - dutch
    - english
    - finnish
    - french
    - german
    - german2
    - hungarian
    - italian
    - kp
    - lovins
    - norwegian
    - porter
    - portuguese
    - romanian
    - russian
    - spanish
    - swedish
    - turkish
  StemmerTokenFilterLanguage:
    type: string
    description: The language to use for a stemmer token filter.
    enum:
    - arabic
    - armenian
    - basque
    - brazilian
    - bulgarian
    - catalan
    - czech
    - danish
    - dutch
    - dutchKp
    - english
    - lightEnglish
    - minimalEnglish
    - possessiveEnglish
    - porter2
    - lovins
    - finnish
    - lightFinnish
    - french
    - lightFrench
    - minimalFrench
    - galician
    - minimalGalician
    - german
    - german2
    - lightGerman
    - minimalGerman
    - greek
    - hindi
    - hungarian
    - lightHungarian
    - indonesian
    - irish
    - italian
    - lightItalian
    - sorani
    - latvian
    - norwegian
    - lightNorwegian
    - minimalNorwegian
    - lightNynorsk
    - minimalNynorsk
    - portuguese
    - lightPortuguese
    - minimalPortuguese
    - portugueseRslp
    - romanian
    - russian
    - lightRussian
    - spanish
    - lightSpanish
    - swedish
    - lightSwedish
    - turkish
  StopwordsList:
    type: string
    description: Identifies a predefined list of language-specific stopwords.
    enum:
    - arabic
    - armenian
    - basque
    - brazilian
    - bulgarian
    - catalan
    - czech
    - danish
    - dutch
    - english
    - finnish
    - french
    - galician
    - german
    - greek
    - hindi
    - hungarian
    - indonesian
    - irish
    - italian
    - latvian
    - norwegian
    - persian
    - portuguese
    - romanian
    - russian
    - sorani
    - spanish
    - swedish
    - thai
    - turkish
  SuggesterSearchMode:
    type: string
    description: Describes the type of suggester to use.
    enum:
    - analyzingInfixMatching
  TokenCharacterKind:
    type: string
    description: Represents classes of characters on which a token filter can operate.
    enum:
    - letter
    - digit
    - whitespace
    - punctuation
    - symbol
  AnalyzeRequest:
    type: object
    properties:
      text:
        type: string
        description: The text to break into tokens.
      analyzer?:
        type: AnalyzerName
        description: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive.
      tokenizer?:
        type: TokenizerName
        description: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive.
      tokenFilters?:
        type: array
        description: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.
        items:
          type: TokenFilterName
      charFilters?:
        type: array
        description: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.
        items:
          type: CharFilterName
    description: The text and analyzer or analysis components to test.
  AnalyzeResult:
    type: object
    properties:
      tokens?:
        type: array
        description: The list of tokens returned by the analyzer specified in the request.
        items:
          type: TokenInfo
    description: The result of testing an analyzer on text.
  Analyzer:
    type: object
    properties:
      '@odata.type':
        type: string
      name:
        type: string
        description: The name of the analyzer. It must only contain letters, digits, spaces, dashes or underscores, can only start and end with alphanumeric characters, and is limited to 128 characters.
    description: Abstract base class for analyzers.
    discriminator: '@odata.type'
  AnalyzerName:
    type: object
    properties:
      name?:
        type: string
    description: Defines the names of all text analyzers supported by Azure Search.
  AsciiFoldingTokenFilter:
    type: TokenFilter
    description: Converts alphabetic, numeric, and symbolic Unicode characters which are not in the first 127 ASCII characters (the "Basic Latin" Unicode block) into their ASCII equivalents, if such equivalents exist. This token filter is implemented using Apache Lucene.
  CharFilter:
    type: object
    properties:
      '@odata.type':
        type: string
      name:
        type: string
    description: Abstract base class for character filters.
    discriminator: '@odata.type'
  CharFilterName:
    type: object
    properties:
      name?:
        type: string
    description: Defines the names of all character filters supported by Azure Search.
  CjkBigramTokenFilter:
    type: TokenFilter
    description: Forms bigrams of CJK terms that are generated from StandardTokenizer. This token filter is implemented using Apache Lucene.
  ClassicTokenizer:
    type: Tokenizer
    description: Grammar-based tokenizer that is suitable for processing most European-language documents. This tokenizer is implemented using Apache Lucene.
  CommonGramTokenFilter:
    type: TokenFilter
    description: Construct bigrams for frequently occurring terms while indexing. Single terms are still indexed too, with bigrams overlaid. This token filter is implemented using Apache Lucene.
  CorsOptions:
    type: object
    properties:
      allowedOrigins:
        type: array
        description: The list of origins from which JavaScript code will be granted access to your index. Can contain a list of hosts of the form {protocol}://{fully-qualified-domain-name}[:{port#}], or a single '*' to allow all origins (not recommended).
        items:
          type: string
      maxAgeInSeconds?:
        type: integer
        description: The duration for which browsers should cache CORS preflight responses. Defaults to 5 mintues.
        format: int64
    description: Defines options to control Cross-Origin Resource Sharing (CORS) for an index.
  CustomAnalyzer:
    type: Analyzer
    description: Allows you to take control over the process of converting text into indexable/searchable tokens. It's a user-defined configuration consisting of a single predefined tokenizer and one or more filters. The tokenizer is responsible for breaking text into tokens, and the filters for modifying tokens emitted by the tokenizer.
  DataChangeDetectionPolicy:
    type: object
    properties:
      '@odata.type':
        type: string
    description: Abstract base class for data change detection policies.
    discriminator: '@odata.type'
  DataContainer:
    type: object
    properties:
      name:
        type: string
        description: The name of the table or view (for Azure SQL data source) or collection (for DocumentDB data source) that will be indexed.
      query?:
        type: string
        description: A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
    description: Represents information about the entity (such as Azure SQL table or DocumentDb collection) that will be indexed.
  DataDeletionDetectionPolicy:
    type: object
    properties:
      '@odata.type':
        type: string
    description: Abstract base class for data deletion detection policies.
    discriminator: '@odata.type'
  DataSource:
    type: object
    properties:
      name:
        type: string
        description: The name of the datasource.
      description?:
        type: string
        description: The description of the datasource.
      type:
        type: DataSourceType
        description: The type of the datasource.
      credentials:
        type: DataSourceCredentials
        description: Credentials for the datasource.
      container:
        type: DataContainer
        description: The data container for the datasource.
      dataChangeDetectionPolicy?:
        type: DataChangeDetectionPolicy
        description: The data change detection policy for the datasource.
      dataDeletionDetectionPolicy?:
        type: DataDeletionDetectionPolicy
        description: The data deletion detection policy for the datasource.
      '@odata.etag?':
        type: string
        description: The ETag of the DataSource.
    description: The definition of the datasource to create or update.
  DataSourceCredentials:
    type: object
    properties:
      connectionString:
        type: string
        description: The connection string for the datasource.
    description: Represents credentials that can be used to connect to a datasource.
  DataSourceListResult:
    type: object
    properties:
      value?:
        type: array
        description: The datasources in the Search service.
        items:
          type: DataSource
    description: Response from a List Datasources request. If successful, it includes the full definitions of all datasources.
  DataSourceType:
    type: object
    properties:
      name?:
        type: string
    description: Defines the type of an Azure Search datasource.
  DataType:
    type: object
    properties:
      name?:
        type: string
    description: Defines the data type of a field in an Azure Search index.
  DictionaryDecompounderTokenFilter:
    type: TokenFilter
    description: Decomposes compound words found in many Germanic languages. This token filter is implemented using Apache Lucene.
  DistanceScoringFunction:
    type: ScoringFunction
    description: Defines a function that boosts scores based on distance from a geographic location.
  DistanceScoringParameters:
    type: object
    properties:
      referencePointParameter:
        type: string
        description: The name of the parameter passed in search queries to specify the reference location.
      boostingDistance:
        type: number
        description: The distance in kilometers from the reference location where the boosting range ends.
        format: double
    description: Provides parameter values to a distance scoring function.
  EdgeNGramTokenFilter:
    type: TokenFilter
    description: Generates n-grams of the given size(s) starting from the front or the back of an input token. This token filter is implemented using Apache Lucene.
  EdgeNGramTokenizer:
    type: Tokenizer
    description: Tokenizes the input from an edge into n-grams of the given size(s). This tokenizer is implemented using Apache Lucene.
  ElisionTokenFilter:
    type: TokenFilter
    description: Removes elisions. For example, "l'avion" (the plane) will be converted to "avion" (plane). This token filter is implemented using Apache Lucene.
  Field:
    type: object
    properties:
      name:
        type: string
        description: The name of the field.
      type:
        type: DataType
        description: The data type of the field.
      analyzer?:
        type: AnalyzerName
        description: The name of the analyzer to use for the field at search time and indexing time. This option can be used only with searchable fields and it can't be set together with either searchAnalyzer or indexAnalyzer. Once the analyzer is chosen, it cannot be changed for the field.
      searchAnalyzer?:
        type: AnalyzerName
        description: The name of the analyzer used at search time for the field. This option can be used only with searchable fields. It must be set together with indexAnalyzer and it cannot be set together with the analyzer option. This analyzer can be updated on an existing field.
      indexAnalyzer?:
        type: AnalyzerName
        description: The name of the analyzer used at indexing time for the field. This option can be used only with searchable fields. It must be set together with searchAnalyzer and it cannot be set together with the analyzer option. Once the analyzer is chosen, it cannot be changed for the field.
      key?:
        type: boolean
        description: A value indicating whether the field is the key of the index. Valid only for string fields. Every index must have exactly one key field.
      searchable?:
        type: boolean
        description: A value indicating whether the field is included in full-text searches. Valid only forstring or string collection fields. Default is false.
      filterable?:
        type: boolean
        description: A value indicating whether the field can be used in filter expressions. Default is false.
      sortable?:
        type: boolean
        description: A value indicating whether the field can be used in orderby expressions. Not valid for string collection fields. Default is false.
      facetable?:
        type: boolean
        description: A value indicating whether it is possible to facet on this field. Not valid for geo-point fields. Default is false.
      retrievable?:
        type: boolean
        description: A value indicating whether the field can be returned in a search result. Default is true.
    description: Represents a field in an index definition in Azure Search, which describes the name, data type, and search behavior of a field.
  FieldMapping:
    type: object
    properties:
      sourceFieldName:
        type: string
        description: The name of the field in the data source.
      targetFieldName?:
        type: string
        description: The name of the target field in the index. Same as the source field name by default.
      mappingFunction?:
        type: FieldMappingFunction
        description: A function to apply to each source field value before indexing.
    description: Defines a mapping between a field in a data source and a target field in an index.
  FieldMappingFunction:
    type: object
    properties:
      name:
        type: string
        description: The name of the field mapping function.
      parameters?:
        type: object
        properties:
          //:
            type: object
        description: A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
    description: Represents a function that transforms a value from a data source before indexing.
  FreshnessScoringFunction:
    type: ScoringFunction
    description: Defines a function that boosts scores based on the value of a date-time field.
  FreshnessScoringParameters:
    type: object
    properties:
      boostingDuration:
        type: string
        description: The expiration period after which boosting will stop for a particular document.
    description: Provides parameter values to a freshness scoring function.
  HighWaterMarkChangeDetectionPolicy:
    type: DataChangeDetectionPolicy
    description: Defines a data change detection policy that captures changes based on the value of a high water mark column.
  Index:
    type: object
    properties:
      name:
        type: string
        description: The name of the index.
      fields:
        type: array
        description: The fields of the index.
        items:
          type: Field
      scoringProfiles?:
        type: array
        description: The scoring profiles for the index.
        items:
          type: ScoringProfile
      defaultScoringProfile?:
        type: string
        description: The name of the scoring profile to use if none is specified in the query. If this property is not set and no scoring profile is specified in the query, then default scoring (tf-idf) will be used.
      corsOptions?:
        type: CorsOptions
        description: Options to control Cross-Origin Resource Sharing (CORS) for the index.
      suggesters?:
        type: array
        description: The suggesters for the index.
        items:
          type: Suggester
      analyzers?:
        type: array
        description: The analyzers for the index.
        items:
          type: Analyzer
      tokenizers?:
        type: array
        description: The tokenizers for the index.
        items:
          type: Tokenizer
      tokenFilters?:
        type: array
        description: The token filters for the index.
        items:
          type: TokenFilter
      charFilters?:
        type: array
        description: The character filters for the index.
        items:
          type: CharFilter
      '@odata.etag?':
        type: string
        description: The ETag of the index.
    description: The definition of the index to create or update.
  IndexGetStatisticsResult:
    type: object
    properties:
      documentCount?:
        type: integer
        description: The number of documents in the index.
        format: int64
      storageSize?:
        type: integer
        description: The amount of storage in bytes consumed by the index.
        format: int64
    description: Statistics for a given index. Statistics are collected periodically and are not guaranteed to always be up-to-date.
  IndexListResult:
    type: object
    properties:
      value?:
        type: array
        description: The indexes in the Search service.
        items:
          type: Index
    description: Response from a List Indexes request. If successful, it includes the full definitions of all indexes.
  Indexer:
    type: object
    properties:
      name:
        type: string
        description: The name of the indexer.
      description?:
        type: string
        description: The description of the indexer.
      dataSourceName:
        type: string
        description: The name of the datasource from which this indexer reads data.
      targetIndexName:
        type: string
        description: The name of the index to which this indexer writes data.
      schedule?:
        type: IndexingSchedule
        description: The schedule for this indexer.
      parameters?:
        type: IndexingParameters
        description: Parameters for indexer execution.
      fieldMappings?:
        type: array
        description: Defines mappings between fields in the data source and corresponding target fields in the index.
        items:
          type: FieldMapping
      disabled?:
        type: boolean
        description: A value indicating whether the indexer is disabled. Default is false.
      '@odata.etag?':
        type: string
        description: The ETag of the Indexer.
    description: The definition of the indexer to create or update.
  IndexerExecutionInfo:
    type: object
    properties:
      status?:
        type: IndexerStatus
        description: Overall indexer status.
      lastResult?:
        type: IndexerExecutionResult
        description: The result of the most recent or an in-progress indexer execution.
      executionHistory?:
        type: array
        description: History of the recent indexer executions, sorted in reverse chronological order.
        items:
          type: IndexerExecutionResult
    description: Represents the current status and execution history of an indexer.
  IndexerExecutionResult:
    type: object
    properties:
      status?:
        type: IndexerExecutionStatus
        description: The outcome of this indexer execution.
      errorMessage?:
        type: string
        description: The error message indicating the top-level error, if any.
      startTime?:
        type: datetime
        description: The start time of this indexer execution.
      endTime?:
        type: datetime
        description: The end time of this indexer execution, if the execution has already completed.
      errors?:
        type: array
        description: The item-level indexing errors
        items:
          type: ItemError
      itemsProcessed?:
        type: integer
        description: The number of items that were processed during this indexer execution. This includes both successfully processed items and items where indexing was attempted but failed.
        format: int32
      itemsFailed?:
        type: integer
        description: The number of items that failed to be indexed during this indexer execution.
        format: int32
      initialTrackingState?:
        type: string
        description: Change tracking state with which an indexer execution started.
      finalTrackingState?:
        type: string
        description: Change tracking state with which an indexer execution finished.
    description: Represents the result of an individual indexer execution.
  IndexerListResult:
    type: object
    properties:
      value?:
        type: array
        description: The indexers in the Search service.
        items:
          type: Indexer
    description: Response from a List Indexers request. If successful, it includes the full definitions of all indexers.
  IndexingParameters:
    type: object
    properties:
      batchSize?:
        type: integer
        description: The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        format: int32
      maxFailedItems?:
        type: integer
        description: The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        format: int32
      maxFailedItemsPerBatch?:
        type: integer
        description: The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        format: int32
      base64EncodeKeys?:
        type: boolean
        description: Whether indexer will base64-encode all values that are inserted into key field of the target index. This is needed if keys can contain characters that are invalid in keys (such as dot '.'). Default is false.
      configuration?:
        type: object
        properties:
          //:
            type: object
        description: A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
    description: Represents parameters for indexer execution.
  IndexingSchedule:
    type: object
    properties:
      interval:
        type: string
        description: The interval of time between indexer executions.
      startTime?:
        type: datetime
        description: The time when an indexer should start running.
    description: Represents a schedule for indexer execution.
  ItemError:
    type: object
    properties:
      key?:
        type: string
        description: The key of the item for which indexing failed.
      errorMessage?:
        type: string
        description: The message describing the error that occurred while attempting to index the item.
    description: Represents an item- or document-level indexing error.
  KeepTokenFilter:
    type: TokenFilter
    description: A token filter that only keeps tokens with text contained in a specified list of words. This token filter is implemented using Apache Lucene.
  KeywordMarkerTokenFilter:
    type: TokenFilter
    description: Marks terms as keywords. This token filter is implemented using Apache Lucene.
  KeywordTokenizer:
    type: Tokenizer
    description: Emits the entire input as a single token. This tokenizer is implemented using Apache Lucene.
  LengthTokenFilter:
    type: TokenFilter
    description: Removes words that are too long or too short. This token filter is implemented using Apache Lucene.
  LimitTokenFilter:
    type: TokenFilter
    description: Limits the number of tokens while indexing. This token filter is implemented using Apache Lucene.
  MagnitudeScoringFunction:
    type: ScoringFunction
    description: Defines a function that boosts scores based on the magnitude of a numeric field.
  MagnitudeScoringParameters:
    type: object
    properties:
      boostingRangeStart:
        type: number
        description: The field value at which boosting starts.
        format: double
      boostingRangeEnd:
        type: number
        description: The field value at which boosting ends.
        format: double
      constantBoostBeyondRange?:
        type: boolean
        description: A value indicating whether to apply a constant boost for field values beyond the range end value; default is false.
    description: Provides parameter values to a magnitude scoring function.
  MappingCharFilter:
    type: CharFilter
    description: A character filter that applies mappings defined with the mappings option. Matching is greedy (longest pattern matching at a given point wins). Replacement is allowed to be the empty string. This character filter is implemented using Apache Lucene.
  MicrosoftLanguageStemmingTokenizer:
    type: Tokenizer
    description: Divides text using language-specific rules and reduces words to their base forms.
  MicrosoftLanguageTokenizer:
    type: Tokenizer
    description: Divides text using language-specific rules.
  NGramTokenFilter:
    type: TokenFilter
    description: Generates n-grams of the given size(s). This token filter is implemented using Apache Lucene.
  NGramTokenizer:
    type: Tokenizer
    description: Tokenizes the input into n-grams of the given size(s). This tokenizer is implemented using Apache Lucene.
  PathHierarchyTokenizer:
    type: Tokenizer
    description: Tokenizer for path-like hierarchies. This tokenizer is implemented using Apache Lucene.
  PatternAnalyzer:
    type: Analyzer
    description: Flexibly separates text into terms via a regular expression pattern. This analyzer is implemented using Apache Lucene.
  PatternCaptureTokenFilter:
    type: TokenFilter
    description: Uses Java regexes to emit multiple tokens - one for each capture group in one or more patterns. This token filter is implemented using Apache Lucene.
  PatternReplaceCharFilter:
    type: CharFilter
    description: A character filter that replaces characters in the input string. It uses a regular expression to identify character sequences to preserve and a replacement pattern to identify characters to replace. For example, given the input text "aa bb aa bb", pattern "(aa)\s+(bb)", and replacement "$1#$2", the result would be "aa#bb aa#bb". This character filter is implemented using Apache Lucene.
  PatternReplaceTokenFilter:
    type: TokenFilter
    description: A character filter that replaces characters in the input string. It uses a regular expression to identify character sequences to preserve and a replacement pattern to identify characters to replace. For example, given the input text "aa bb aa bb", pattern "(aa)\s+(bb)", and replacement "$1#$2", the result would be "aa#bb aa#bb". This token filter is implemented using Apache Lucene.
  PatternTokenizer:
    type: Tokenizer
    description: Tokenizer that uses regex pattern matching to construct distinct tokens. This tokenizer is implemented using Apache Lucene.
  PhoneticTokenFilter:
    type: TokenFilter
    description: Create tokens for phonetic matches. This token filter is implemented using Apache Lucene.
  RegexFlags:
    type: object
    properties:
      name?:
        type: string
    description: Defines flags that can be combined to control how regular expressions are used in the pattern analyzer and pattern tokenizer.
  ScoringFunction:
    type: object
    properties:
      type:
        type: string
      fieldName:
        type: string
        description: The name of the field used as input to the scoring function.
      boost:
        type: number
        description: A multiplier for the raw score. Must be a positive number not equal to 1.0.
        format: double
      interpolation?:
        type: ScoringFunctionInterpolation
        description: A value indicating how boosting will be interpolated across document scores; defaults to "Linear".
    description: Abstract base class for functions that can modify document scores during ranking.
    discriminator: type
  ScoringProfile:
    type: object
    properties:
      name:
        type: string
        description: The name of the scoring profile.
      text?:
        type: TextWeights
        description: Parameters that boost scoring based on text matches in certain index fields.
      functions?:
        type: array
        description: The collection of functions that influence the scoring of documents.
        items:
          type: ScoringFunction
      functionAggregation?:
        type: ScoringFunctionAggregation
        description: A value indicating how the results of individual scoring functions should be combined. Defaults to "Sum". Ignored if there are no scoring functions.
    description: Defines parameters for an Azure Search index that influence scoring in search queries.
  ShingleTokenFilter:
    type: TokenFilter
    description: Creates combinations of tokens as a single token. This token filter is implemented using Apache Lucene.
  SnowballTokenFilter:
    type: TokenFilter
    description: A filter that stems words using a Snowball-generated stemmer. This token filter is implemented using Apache Lucene.
  SoftDeleteColumnDeletionDetectionPolicy:
    type: DataDeletionDetectionPolicy
    description: Defines a data deletion detection policy that implements a soft-deletion strategy. It determines whether an item should be deleted based on the value of a designated 'soft delete' column.
  SqlIntegratedChangeTrackingPolicy:
    type: DataChangeDetectionPolicy
    description: Defines a data change detection policy that captures changes using the Integrated Change Tracking feature of Azure SQL Database.
  StandardAnalyzer:
    type: Analyzer
    description: Standard Apache Lucene analyzer; Composed of the standard tokenizer, lowercase filter and stop filter.
  StandardTokenizer:
    type: Tokenizer
    description: Breaks text following the Unicode Text Segmentation rules. This tokenizer is implemented using Apache Lucene.
  StemmerOverrideTokenFilter:
    type: TokenFilter
    description: Provides the ability to override other stemming filters with custom dictionary-based stemming. Any dictionary-stemmed terms will be marked as keywords so that they will not be stemmed with stemmers down the chain. Must be placed before any stemming filters. This token filter is implemented using Apache Lucene.
  StemmerTokenFilter:
    type: TokenFilter
    description: Language specific stemming filter. This token filter is implemented using Apache Lucene.
  StopAnalyzer:
    type: Analyzer
    description: Divides text at non-letters; Applies the lowercase and stopword token filters. This analyzer is implemented using Apache Lucene.
  StopwordsTokenFilter:
    type: TokenFilter
    description: Removes stop words from a token stream. This token filter is implemented using Apache Lucene.
  Suggester:
    type: object
    properties:
      name:
        type: string
        description: The name of the suggester.
      searchMode:
        type: SuggesterSearchMode
        description: A value indicating the capabilities of the suggester.
      sourceFields:
        type: array
        description: The list of field names to which the suggester applies. Each field must be searchable.
        items:
          type: string
    description: Defines how the Suggest API should apply to a group of fields in the index.
  SynonymTokenFilter:
    type: TokenFilter
    description: Matches single or multi-word synonyms in a token stream. This token filter is implemented using Apache Lucene.
  TagScoringFunction:
    type: ScoringFunction
    description: Defines a function that boosts scores of documents with string values matching a given list of tags.
  TagScoringParameters:
    type: object
    properties:
      tagsParameter:
        type: string
        description: The name of the parameter passed in search queries to specify the list of tags to compare against the target field.
    description: Provides parameter values to a tag scoring function.
  TextWeights:
    type: object
    properties:
      weights:
        type: object
        properties:
          //:
            type: number
            format: double
        description: The dictionary of per-field weights to boost document scoring. The keys are field names and the values are the weights for each field.
    description: Defines weights on index fields for which matches should boost scoring in search queries.
  TokenFilter:
    type: object
    properties:
      '@odata.type':
        type: string
      name:
        type: string
    description: Abstract base class for token filters.
    discriminator: '@odata.type'
  TokenFilterName:
    type: object
    properties:
      name?:
        type: string
    description: Defines the names of all token filters supported by Azure Search.
  TokenInfo:
    type: object
    properties:
      token?:
        type: string
        description: The token returned by the analyzer.
      startOffset?:
        type: integer
        description: The index of the first character of the token in the input text.
        format: int32
      endOffset?:
        type: integer
        description: The index of the last character of the token in the input text.
        format: int32
      position?:
        type: integer
        description: The position of the token in the input text relative to other tokens. The first token in the input text has position 0, the next has position 1, and so on. Depending on the analyzer used, some tokens might have the same position, for example if they are synonyms of each other.
        format: int32
    description: Information about a token returned by an analyzer.
  Tokenizer:
    type: object
    properties:
      '@odata.type':
        type: string
      name:
        type: string
    description: Abstract base class for tokenizers.
    discriminator: '@odata.type'
  TokenizerName:
    type: object
    properties:
      name?:
        type: string
    description: Defines the names of all tokenizers supported by Azure Search.
  TruncateTokenFilter:
    type: TokenFilter
    description: Truncates the terms to a specific length. This token filter is implemented using Apache Lucene.
  UaxUrlEmailTokenizer:
    type: Tokenizer
    description: Tokenizes urls and emails as one token. This tokenizer is implemented using Apache Lucene.
  UniqueTokenFilter:
    type: TokenFilter
    description: Filters out tokens with same text as the previous token. This token filter is implemented using Apache Lucene.
  WordDelimiterTokenFilter:
    type: TokenFilter
    description: Splits words into subwords and performs optional transformations on subword groups. This token filter is implemented using Apache Lucene.
/datasources:
  get:
    description: Lists all datasources available for an Azure Search service.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
  post:
    description: Creates a new Azure Search datasource.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
    body:
      application/json: DataSource
/datasources('{dataSourceName}'):
  uriParameters:
    dataSourceName:
      type: string
      description: The name of the datasource to retrieve.
      displayName: dataSourceName
  get:
    description: Retrieves a datasource definition from Azure Search.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
  delete:
    description: Deletes an Azure Search datasource.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
      If-Match?:
        type: string
        description: Defines the If-Match condition. The operation will be performed only if the ETag on the server matches this value.
        displayName: If-Match
      If-None-Match?:
        type: string
        description: Defines the If-None-Match condition. The operation will be performed only if the ETag on the server does not match this value.
        displayName: If-None-Match
  put:
    description: Creates a new Azure Search datasource or updates a datasource if it already exists.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
      If-Match?:
        type: string
        description: Defines the If-Match condition. The operation will be performed only if the ETag on the server matches this value.
        displayName: If-Match
      If-None-Match?:
        type: string
        description: Defines the If-None-Match condition. The operation will be performed only if the ETag on the server does not match this value.
        displayName: If-None-Match
    body:
      application/json: DataSource
/indexers:
  get:
    description: Lists all indexers available for an Azure Search service.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
  post:
    description: Creates a new Azure Search indexer.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
    body:
      application/json: Indexer
/indexers('{indexerName}'):
  uriParameters:
    indexerName:
      type: string
      description: The name of the indexer to retrieve.
      displayName: indexerName
  /search.reset:
    post:
      description: Resets the change tracking state associated with an Azure Search indexer.
      queryParameters:
        api-version:
          type: string
          description: Client Api Version.
          displayName: api-version
      headers:
        client-request-id?:
          type: string
          description: The tracking ID sent with the request to help with debugging.
          displayName: client-request-id
  /search.run:
    post:
      description: Runs an Azure Search indexer on-demand.
      queryParameters:
        api-version:
          type: string
          description: Client Api Version.
          displayName: api-version
      headers:
        client-request-id?:
          type: string
          description: The tracking ID sent with the request to help with debugging.
          displayName: client-request-id
  /search.status:
    get:
      description: Returns the current status and execution history of an indexer.
      queryParameters:
        api-version:
          type: string
          description: Client Api Version.
          displayName: api-version
      headers:
        client-request-id?:
          type: string
          description: The tracking ID sent with the request to help with debugging.
          displayName: client-request-id
  get:
    description: Retrieves an indexer definition from Azure Search.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
  delete:
    description: Deletes an Azure Search indexer.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
      If-Match?:
        type: string
        description: Defines the If-Match condition. The operation will be performed only if the ETag on the server matches this value.
        displayName: If-Match
      If-None-Match?:
        type: string
        description: Defines the If-None-Match condition. The operation will be performed only if the ETag on the server does not match this value.
        displayName: If-None-Match
  put:
    description: Creates a new Azure Search indexer or updates an indexer if it already exists.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
      If-Match?:
        type: string
        description: Defines the If-Match condition. The operation will be performed only if the ETag on the server matches this value.
        displayName: If-Match
      If-None-Match?:
        type: string
        description: Defines the If-None-Match condition. The operation will be performed only if the ETag on the server does not match this value.
        displayName: If-None-Match
    body:
      application/json: Indexer
/indexes:
  get:
    description: Lists all indexes available for an Azure Search service.
    queryParameters:
      $select?:
        type: string
        description: Selects which properties of the index definitions to retrieve. Specified as a comma-separated list of JSON property names, or '*' for all properties. The default is all properties.
        displayName: $select
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
  post:
    description: Creates a new Azure Search index.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
    body:
      application/json: Index
/indexes('{indexName}'):
  uriParameters:
    indexName:
      type: string
      description: The name of the index to retrieve.
      displayName: indexName
  /search.analyze:
    post:
      description: Shows how an analyzer breaks text into tokens.
      queryParameters:
        api-version:
          type: string
          description: Client Api Version.
          displayName: api-version
      headers:
        client-request-id?:
          type: string
          description: The tracking ID sent with the request to help with debugging.
          displayName: client-request-id
      body:
        application/json: AnalyzeRequest
  /search.stats:
    get:
      description: Returns statistics for the given index, including a document count and storage usage.
      queryParameters:
        api-version:
          type: string
          description: Client Api Version.
          displayName: api-version
      headers:
        client-request-id?:
          type: string
          description: The tracking ID sent with the request to help with debugging.
          displayName: client-request-id
  get:
    description: Retrieves an index definition from Azure Search.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
  delete:
    description: Deletes an Azure Search index and all the documents it contains.
    queryParameters:
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
      If-Match?:
        type: string
        description: Defines the If-Match condition. The operation will be performed only if the ETag on the server matches this value.
        displayName: If-Match
      If-None-Match?:
        type: string
        description: Defines the If-None-Match condition. The operation will be performed only if the ETag on the server does not match this value.
        displayName: If-None-Match
  put:
    description: Creates a new Azure Search index or updates an index if it already exists.
    queryParameters:
      allowIndexDowntime?:
        type: boolean
        description: Allows new analyzers, tokenizers, token filters, or char filters to be added to an index by taking the index offline for at least a few seconds. This temporarily causes indexing and query requests to fail. Performance and write availability of the index can be impaired for several minutes after the index is updated, or longer for very large indexes.
        displayName: allowIndexDowntime
      api-version:
        type: string
        description: Client Api Version.
        displayName: api-version
    headers:
      client-request-id?:
        type: string
        description: The tracking ID sent with the request to help with debugging.
        displayName: client-request-id
      If-Match?:
        type: string
        description: Defines the If-Match condition. The operation will be performed only if the ETag on the server matches this value.
        displayName: If-Match
      If-None-Match?:
        type: string
        description: Defines the If-None-Match condition. The operation will be performed only if the ETag on the server does not match this value.
        displayName: If-None-Match
    body:
      application/json: Index
